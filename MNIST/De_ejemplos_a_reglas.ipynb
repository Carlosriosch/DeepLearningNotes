{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhOTKiz-4-Ly"
   },
   "source": [
    "<a href=\"https://github.com/Carlosriosch/DeepLearningNotes/blob/master/MNIST/De_ejemplos_a_reglas.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# De ejemplos a reglas\n",
    "En este notebook se muestra como generar un programa a partir de ejemplos usando TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WtyBxheo4uy3",
    "outputId": "48c37289-e048-4327-d2b1-c716c52e5f79"
   },
   "outputs": [],
   "source": [
    "# Se incluyen las bibliotecas necesarias\n",
    "#%tensorflow_version 2.x\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oj4lwAoZKJ4u"
   },
   "source": [
    "# Generar Datos de prueba\n",
    "\n",
    "Definimos una función simple y generamos ejemplos de prueba, en este caso:\n",
    "* las reglas son definidas por la función `f(x)`\n",
    "* la variable `xs` contiene todos los **inputs** \n",
    "* la variable `ys` contiene todos los **outputs**\n",
    "\n",
    "En este ejemplo, la función definida es $f(x) = x + 5$, y generamos un *dataset* con 20 ejemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SqOH6eS6-pb"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  return x + 5\n",
    "xs = np.arange(0,10,0.5) #Así funcióna arrange np.arrange(desde que numero, hasta que numero, con cuanto de incremento)\n",
    "ys = f(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo08_c656gPt"
   },
   "outputs": [],
   "source": [
    "# reset de la sesión, en caso de querer reentrenar el modelo\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rJdVX1OBNlg"
   },
   "source": [
    "# Neurona Artificial\n",
    "Este modelo consta de una sola neurona, con un solo input. Se incluye la imágen de la presentación para recordar el concepto de neurona artifical.\n",
    "\n",
    "<img alt='perceptron' src='./img/Perceptron.png' width=\"300\"/>\n",
    "\n",
    "Recordar que la función que se ejecuta en la neurona es $\\varphi \\left( \\mathbf{w} \\cdot \\mathbf{x} + b \\right)$ donde:\n",
    "* $\\varphi$ es una función arbitratia, derivable, usualmente no lineal\n",
    "* $\\mathbf{w}$ son los coeficientes de cada *input* \n",
    "* $b$ es el *bias*, un parámetro entrenable que no depende de los valores de entrada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X12H7qE5BLOV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])]) #Con esto decimos que el model sera una capa de una sola unidad conectada (dense) a todos los parametros que en este caso es uno y el bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiSV9Mx0Kr8K"
   },
   "source": [
    "Compilamos el modelo, indicando la función de optimización que deseamos utilizar. En este caso, la función es [Stochastic Gradient Descent](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD?version=stable). \n",
    "\n",
    "Además, indicamos la función a optimizar (o *loss function*, pues se busca minimizar la \"perdida\" o *loss*). En este caso, usamos el [Mean Squared Error](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE?version=stable) o \"error cuadrado promedio\". Esta función es adecuada para problemas de regresión, pues penaliza con más severidad a los valores más lejanos al valor de entrenamiento dado por los ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yo_FA8xD6qvk"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3YKW0zkMCcl"
   },
   "source": [
    "Podemos ver un resumen del modelo, que nos indica información útil como el detalle de cada *layer* y la cantidad de parámetros del modelo.\n",
    "\n",
    "En este caso contamos con una sola neurona, y por lo tanto 2 parámetros:\n",
    "1. el coeficiente que se multiplica al valor de entrada.\n",
    "2. el valor de *bias* que se suma a la combinación lineal de valores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "pnqlOSYg68fl",
    "outputId": "952a7de2-d672-4cbe-e4cc-d4c809ebdd27",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 1)                 2         \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXHd27BWNMn4"
   },
   "source": [
    "# Entrenando la red neuronal\n",
    "El entrenamiento consiste en actualizar los parámetros del modelo basado en los ejemplos del *dataset*. En cada *epoch*, se muestra todo el *dataset* y se actualizan los parámetros del modelo. En este ejemplo, usamos 500 *epochs* para entrenar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mfQgCSrc7JEA",
    "outputId": "6b56b756-72df-4ddb-e161-087b8ec5fcf3",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " 4ms/step - loss: 0.2707\nEpoch 252/500\n1/1 [==============================] - 0s 0s/step - loss: 0.2672\nEpoch 253/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.2637\nEpoch 254/500\n1/1 [==============================] - 0s 0s/step - loss: 0.2603\nEpoch 255/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.2569\nEpoch 256/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.2536\nEpoch 257/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.2503\nEpoch 258/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.2471\nEpoch 259/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.2439\nEpoch 260/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.2408\nEpoch 261/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.2376\nEpoch 262/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.2346\nEpoch 263/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.2315\nEpoch 264/500\n1/1 [==============================] - ETA: 0s - loss: 0.2281/1 [==============================] - 0s 5ms/step - loss: 0.2285\nEpoch 265/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.2256\nEpoch 266/500\n1/1 [==============================] - 0s 998us/step - loss: 0.2227\nEpoch 267/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.2198\nEpoch 268/500\n1/1 [==============================] - 0s 7ms/step - loss: 0.2170\nEpoch 269/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.2141\nEpoch 270/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.2114\nEpoch 271/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.2086\nEpoch 272/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.2060\nEpoch 273/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.2033\nEpoch 274/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.2007\nEpoch 275/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.1981\nEpoch 276/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.1955\nEpoch 277/500\n1/1 [==============================] - 0s 8ms/step - loss: 0.1930\nEpoch 278/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1905\nEpoch 279/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1880\nEpoch 280/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1856\nEpoch 281/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1832\nEpoch 282/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.1808\nEpoch 283/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1785\nEpoch 284/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1762\nEpoch 285/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1739\nEpoch 286/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1717\nEpoch 287/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1694\nEpoch 288/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1672\nEpoch 289/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1651\nEpoch 290/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1630\nEpoch 291/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.1608\nEpoch 292/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1588\nEpoch 293/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.1567\nEpoch 294/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1547\nEpoch 295/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.1527\nEpoch 296/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.1507\nEpoch 297/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.1488\nEpoch 298/500\n1/1 [==============================] - 0s 998us/step - loss: 0.1468\nEpoch 299/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1449\nEpoch 300/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1431\nEpoch 301/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1412\nEpoch 302/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1394\nEpoch 303/500\n1/1 [==============================] - 0s 532us/step - loss: 0.1376\nEpoch 304/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1358\nEpoch 305/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1341\nEpoch 306/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1323\nEpoch 307/500\n1/1 [==============================] - 0s 998us/step - loss: 0.1306\nEpoch 308/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1289\nEpoch 309/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1273\nEpoch 310/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1256\nEpoch 311/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1240\nEpoch 312/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.1224\nEpoch 313/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1208\nEpoch 314/500\n1/1 [==============================] - 0s 8ms/step - loss: 0.1192\nEpoch 315/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1177\nEpoch 316/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.1162\nEpoch 317/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1147\nEpoch 318/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1132\nEpoch 319/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1117\nEpoch 320/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1103\nEpoch 321/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1089\nEpoch 322/500\n1/1 [==============================] - 0s 16ms/step - loss: 0.1075\nEpoch 323/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.1061\nEpoch 324/500\n1/1 [==============================] - 0s 0s/step - loss: 0.1047\nEpoch 325/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.1033\nEpoch 326/500\n1/1 [==============================] - 0s 999us/step - loss: 0.1020\nEpoch 327/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.1007\nEpoch 328/500\n1/1 [==============================] - 0s 527us/step - loss: 0.0994\nEpoch 329/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0981\nEpoch 330/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0968\nEpoch 331/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0956\nEpoch 332/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0943\nEpoch 333/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0931\nEpoch 334/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0919\nEpoch 335/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0907\nEpoch 336/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0896\nEpoch 337/500\n1/1 [==============================] - 0s 15ms/step - loss: 0.0884\nEpoch 338/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0873\nEpoch 339/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0861\nEpoch 340/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0850\nEpoch 341/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0839\nEpoch 342/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0828\nEpoch 343/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0818\nEpoch 344/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0807\nEpoch 345/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0797\nEpoch 346/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0786\nEpoch 347/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0776\nEpoch 348/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0766\nEpoch 349/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0756\nEpoch 350/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0747\nEpoch 351/500\n1/1 [==============================] - 0s 8ms/step - loss: 0.0737\nEpoch 352/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0727\nEpoch 353/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0718\nEpoch 354/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0709\nEpoch 355/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0699\nEpoch 356/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0690\nEpoch 357/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0682\nEpoch 358/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0673\nEpoch 359/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0664\nEpoch 360/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0655\nEpoch 361/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0647\nEpoch 362/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0639\nEpoch 363/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0630\nEpoch 364/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0622\nEpoch 365/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0614\nEpoch 366/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0606\nEpoch 367/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0598\nEpoch 368/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0591\nEpoch 369/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0583\nEpoch 370/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0575\nEpoch 371/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0568\nEpoch 372/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0561\nEpoch 373/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0553\nEpoch 374/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0546\nEpoch 375/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0539\nEpoch 376/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0532\nEpoch 377/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0525\nEpoch 378/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0519\nEpoch 379/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0512\nEpoch 380/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0505\nEpoch 381/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0499\nEpoch 382/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0492\nEpoch 383/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0486\nEpoch 384/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0480\nEpoch 385/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0473\nEpoch 386/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0467\nEpoch 387/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0461\nEpoch 388/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0455\nEpoch 389/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0449\nEpoch 390/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0444\nEpoch 391/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0438\nEpoch 392/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0432\nEpoch 393/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0427\nEpoch 394/500\n1/1 [==============================] - 0s 9ms/step - loss: 0.0421\nEpoch 395/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0416\nEpoch 396/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0410\nEpoch 397/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0405\nEpoch 398/500\n1/1 [==============================] - 0s 931us/step - loss: 0.0400\nEpoch 399/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0395\nEpoch 400/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0390\nEpoch 401/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0384\nEpoch 402/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0379\nEpoch 403/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0375\nEpoch 404/500\n1/1 [==============================] - 0s 7ms/step - loss: 0.0370\nEpoch 405/500\n1/1 [==============================] - 0s 7ms/step - loss: 0.0365\nEpoch 406/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0360\nEpoch 407/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0356\nEpoch 408/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0351\nEpoch 409/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0346\nEpoch 410/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0342\nEpoch 411/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0338\nEpoch 412/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0333\nEpoch 413/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0329\nEpoch 414/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0325\nEpoch 415/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0320\nEpoch 416/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0316\nEpoch 417/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0312\nEpoch 418/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0308\nEpoch 419/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0304\nEpoch 420/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0300\nEpoch 421/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0296\nEpoch 422/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0293\nEpoch 423/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0289\nEpoch 424/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0285\nEpoch 425/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0281\nEpoch 426/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0278\nEpoch 427/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0274\nEpoch 428/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0271\nEpoch 429/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0267\nEpoch 430/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0264\nEpoch 431/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0260\nEpoch 432/500\n1/1 [==============================] - 0s 997us/step - loss: 0.0257\nEpoch 433/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0254\nEpoch 434/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0250\nEpoch 435/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0247\nEpoch 436/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0244\nEpoch 437/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0241\nEpoch 438/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0238\nEpoch 439/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0235\nEpoch 440/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0231\nEpoch 441/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0228\nEpoch 442/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0226\nEpoch 443/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0223\nEpoch 444/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0220\nEpoch 445/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0217\nEpoch 446/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0214\nEpoch 447/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0211\nEpoch 448/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0209\nEpoch 449/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0206\nEpoch 450/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0203\nEpoch 451/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0201\nEpoch 452/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0198\nEpoch 453/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0195\nEpoch 454/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0193\nEpoch 455/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0190\nEpoch 456/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0188\nEpoch 457/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0186\nEpoch 458/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0183\nEpoch 459/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0181\nEpoch 460/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0178\nEpoch 461/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0176\nEpoch 462/500\n1/1 [==============================] - 0s 7ms/step - loss: 0.0174\nEpoch 463/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0172\nEpoch 464/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0169\nEpoch 465/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0167\nEpoch 466/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0165\nEpoch 467/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0163\nEpoch 468/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0161\nEpoch 469/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0159\nEpoch 470/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0157\nEpoch 471/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0155\nEpoch 472/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0153\nEpoch 473/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0151\nEpoch 474/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0149\nEpoch 475/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0147\nEpoch 476/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0145\nEpoch 477/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0143\nEpoch 478/500\n1/1 [==============================] - 0s 1ms/step - loss: 0.0141\nEpoch 479/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0139\nEpoch 480/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0138\nEpoch 481/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0136\nEpoch 482/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0134\nEpoch 483/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0132\nEpoch 484/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0131\nEpoch 485/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0129\nEpoch 486/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0127\nEpoch 487/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0126\nEpoch 488/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0124\nEpoch 489/500\n1/1 [==============================] - 0s 996us/step - loss: 0.0122\nEpoch 490/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0121\nEpoch 491/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0119\nEpoch 492/500\n1/1 [==============================] - 0s 3ms/step - loss: 0.0118\nEpoch 493/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0116\nEpoch 494/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0115\nEpoch 495/500\n1/1 [==============================] - 0s 0s/step - loss: 0.0113\nEpoch 496/500\n1/1 [==============================] - 0s 6ms/step - loss: 0.0112\nEpoch 497/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0110\nEpoch 498/500\n1/1 [==============================] - 0s 2ms/step - loss: 0.0109\nEpoch 499/500\n1/1 [==============================] - 0s 5ms/step - loss: 0.0107\nEpoch 500/500\n1/1 [==============================] - 0s 4ms/step - loss: 0.0106\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x156ebefe648>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500) #Cuando ya tenemos el modelo armado con Tf, entonces lo ajustamos a nuestros datos y con nuestros labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSqjB5udTNuk"
   },
   "source": [
    "Una vez que el modelo está entrenado, podemos determinar su presición imprimiendo un valor conocido, y comparándolo con el valor real generado por la\n",
    "función `f` que queremos aproximar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vE-OpwkF7LvF",
    "outputId": "ef0705c0-f41f-4b88-ad3d-6455f71c9afb",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[9.972493]]\n"
    }
   ],
   "source": [
    "print(model.predict([5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8Vaa0F1Tk5L"
   },
   "source": [
    "Quizás sea sorpresivo que el valor no es exactamente igual a 10 luego de entrenar el modelo con 500 iteraciones del *dataset*.\n",
    "\n",
    "Por esto es importante recordar que las redes neuronales se\n",
    "entrenan calculando probabilidades, y el modelo aprendió que existe una relación entre los *inputs* y *outputs* que es altamente probable dados los ejemplos en el *dataset*. Aún así, \"altamente probable\" no significa \"exactamente\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi que la forma en la que predict se acerca al valor real varía, así que voy a graficar ambos valores para ver si en algun rato converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 248.518125 \r\nL 368.925 248.518125 \r\nL 368.925 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 361.725 224.64 \r\nL 361.725 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m79e57e89cb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m79e57e89cb\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(38.961932 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"109.779545\" xlink:href=\"#m79e57e89cb\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(106.598295 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"177.415909\" xlink:href=\"#m79e57e89cb\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(174.234659 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.052273\" xlink:href=\"#m79e57e89cb\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(241.871023 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"312.688636\" xlink:href=\"#m79e57e89cb\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(309.507386 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m557a30699a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m557a30699a\" y=\"189.652849\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 6 -->\r\n      <g transform=\"translate(13.5625 193.452068)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m557a30699a\" y=\"147.002223\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 8 -->\r\n      <g transform=\"translate(13.5625 150.801442)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m557a30699a\" y=\"104.351597\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 108.150816)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m557a30699a\" y=\"61.700971\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 12 -->\r\n      <g transform=\"translate(7.2 65.500189)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m557a30699a\" y=\"19.050345\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 14 -->\r\n      <g transform=\"translate(7.2 22.849563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_11\">\r\n    <path clip-path=\"url(#pb2a6bb85e2)\" d=\"M 42.143182 214.756364 \r\nL 75.961364 192.792731 \r\nL 109.779545 170.829098 \r\nL 143.597727 148.865455 \r\nL 177.415909 126.901832 \r\nL 211.234091 104.938189 \r\nL 245.052273 82.974545 \r\nL 278.870455 61.010923 \r\nL 312.688636 39.04728 \r\nL 346.506818 17.083636 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#pb2a6bb85e2)\" d=\"M 42.143182 210.978162 \r\nL 75.961364 189.652849 \r\nL 109.779545 168.327536 \r\nL 143.597727 147.002223 \r\nL 177.415909 125.67691 \r\nL 211.234091 104.351597 \r\nL 245.052273 83.026284 \r\nL 278.870455 61.700971 \r\nL 312.688636 40.375658 \r\nL 346.506818 19.050345 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 361.725 224.64 \r\nL 361.725 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 361.725 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 361.725 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pb2a6bb85e2\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "pr=[]\n",
    "re=[]\n",
    "for i in range(10):\n",
    "    #print(model.predict([i]))\n",
    "    pr.append(float(model.predict([i])))\n",
    "    re.append(float(i+5))\n",
    "plt.plot(pr)\n",
    "plt.plot(re)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "[Clase 1] 1 - De ejemplos a reglas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1594597533665"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}